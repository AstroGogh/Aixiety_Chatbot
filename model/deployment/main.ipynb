{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vincencius\\anaconda3\\envs\\aixiety\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import truss\n",
    "from pathlib import Path\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<truss.truss_handle.TrussHandle object at 0x0000013D0B53C790>\n"
     ]
    }
   ],
   "source": [
    "#Containerize Model\n",
    "tr = truss.load(Path(\"/llama-2-7b-aixiety\"))\n",
    "# command = tr.docker_build_setup(build_dir=Path(\"./llama-2-7b-aixiety-v2\"))\n",
    "\n",
    "print(tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'docker build llama-2-7b-aixiety -t custom-model:latest'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr.docker_build_setup(build_dir=Path(\"./llama-2-7b-aixiety\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOS, EOS = \"<s>\", \"</s>\"\n",
    "B_INST, E_INST = \"[INST]\", \"[/INST]\"\n",
    "B_SYS, E_SYS = \"<<SYS>>\\n\", \"\\n<</SYS>>\\n\\n\"\n",
    "DEFAULT_SYSTEM_PROMPT = \"\"\"\\\n",
    "Anda adalah psikolog berlisensi, harap berikan pasien ini tanggapan yang bermanfaat untuk kekhawatiran mereka. \n",
    "Pastikan mereka merasa nyaman dengan bertanya untuk memahami masalah mereka terlebih dahulu. \n",
    "Jika topik berada diluar ranah psikolog, alihkan pembicaraan mengenai kesehatan mental pasien.\"\"\"\n",
    "\n",
    "\n",
    "def format_to_llama_chat_style(history) -> str:\n",
    "    # history is now a list of dictionaries with \"instruction\" and \"response\" keys\n",
    "    prompt = \"\"\n",
    "    current_length = 0\n",
    "\n",
    "    for i, dialog in enumerate(history[:-1]):\n",
    "        print(\"Urutan ke-\", i)\n",
    "        instruction, response = dialog[\"instruction\"], dialog[\"response\"]\n",
    "\n",
    "        # Calculate the length of the current dialog\n",
    "        dialog_length = len(instruction.strip()) + len(response.strip())\n",
    "\n",
    "        # Check if adding this dialog would exceed the maximum length\n",
    "        if current_length + dialog_length > 1024:\n",
    "            break  # Stop adding more dialogues if the limit is reached\n",
    "\n",
    "        # prepend system instruction before first instruction\n",
    "        if i == 0:\n",
    "            instruction = f\"{B_SYS}{DEFAULT_SYSTEM_PROMPT}{E_SYS}\" + instruction\n",
    "        else:\n",
    "            # the tokenizer automatically adds a bos_token during encoding,\n",
    "            # for this reason the bos_token is not added for the first instruction\n",
    "            prompt += BOS\n",
    "        prompt += f\"{B_INST} {instruction.strip()} {E_INST} {response.strip()} \" + EOS\n",
    "\n",
    "    # new instruction from the user\n",
    "    new_instruction = history[-1][\"instruction\"].strip()\n",
    "\n",
    "    # the tokenizer automatically adds a bos_token during encoding,\n",
    "    # for this reason the bos_token is not added for the first instruction\n",
    "    if len(history) > 1:\n",
    "        prompt += BOS\n",
    "    else:\n",
    "        # prepend system instruction before the first instruction\n",
    "        new_instruction = f\"{B_SYS}{DEFAULT_SYSTEM_PROMPT}{E_SYS}\" + new_instruction\n",
    "\n",
    "    prompt += f\"{B_INST} {new_instruction} {E_INST}\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {'history': [\n",
    "    {\n",
    "        'instruction': \"gua merasa sedih belakangan ini karena diputusin\",\n",
    "        'response': 'Penting untuk diingat bahwa putusan adalah bagian dari kehidupan, dan penting untuk mencari dukungan saat Anda mengalami emosi yang sulit. Mari kita bekerja mengembangkan strategi untuk membantu Anda mengatasi perasaan Anda dan menemukan cara yang sehat untuk mengekspresikan emosi Anda.'\n",
    "    },\n",
    "    {\n",
    "        'instruction': 'berapa 1+1?',\n",
    "        'response': ''\n",
    "    }\n",
    "]}\n",
    "\n",
    "# print(history)\n",
    "# history = history.pop(\"history\")\n",
    "# prompt = format_to_llama_chat_style(history)\n",
    "# print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': '  Sangat baik! 1 + 1 adalah 2. ðŸ˜Š'}\n"
     ]
    }
   ],
   "source": [
    "res = requests.post(\"http://34.66.79.181:8080/v1/models/model:predict\", json=history)\n",
    "res.close()\n",
    "print(res.json())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aixiety",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
